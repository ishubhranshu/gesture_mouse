{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import joblib  # For saving preprocessing objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x0   y0   z0        x1        y1        z1        x2        y2        z2  \\\n",
      "0  0.0  0.0  0.0 -0.392565 -0.919682 -0.008832 -0.934683 -1.653227 -0.104695   \n",
      "1  0.0  0.0  0.0 -0.382321 -0.924016 -0.005059 -0.929391 -1.621596 -0.093823   \n",
      "2  0.0  0.0  0.0 -0.380313 -0.924858  0.000236 -0.920760 -1.616901 -0.085726   \n",
      "3  0.0  0.0  0.0 -0.384318 -0.923200  0.001457 -0.929509 -1.610901 -0.083880   \n",
      "4  0.0  0.0  0.0 -0.386397 -0.922309  0.006655 -0.927815 -1.607206 -0.074216   \n",
      "\n",
      "         x3  ...       x18       y18       z18       x19       y19       z19  \\\n",
      "0 -1.197211  ... -1.646735  0.433878 -0.387121 -1.457390  0.390764 -0.248514   \n",
      "1 -1.210147  ... -1.670208  0.400080 -0.337246 -1.483472  0.338630 -0.204564   \n",
      "2 -1.204311  ... -1.661572  0.398968 -0.321018 -1.474025  0.343727 -0.188450   \n",
      "3 -1.217913  ... -1.681630  0.391187 -0.338452 -1.494125  0.326067 -0.204869   \n",
      "4 -1.221105  ... -1.682880  0.390643 -0.315095 -1.502074  0.328198 -0.179706   \n",
      "\n",
      "        x20       y20       z20  class  \n",
      "0 -1.245902  0.388014 -0.148372      3  \n",
      "1 -1.277963  0.343198 -0.109214      3  \n",
      "2 -1.269789  0.346622 -0.094310      3  \n",
      "3 -1.286553  0.330681 -0.107987      3  \n",
      "4 -1.299393  0.335350 -0.083677      3  \n",
      "\n",
      "[5 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('hand_gesture_data.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = df.drop('class', axis=1).values  # Features: normalized landmarks\n",
    "y = df['class'].values               # Labels: gesture classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 4000\n",
      "Testing samples: 1000\n"
     ]
    }
   ],
   "source": [
    "# Split the data (e.g., 80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]}')\n",
    "print(f'Testing samples: {X_test.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Optional: Save the scaler for future use (e.g., during inference)\n",
    "joblib.dump(scaler, 'scaler.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ishub\\anaconda3\\envs\\hand_gesture\\lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,773</span> (65.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,773\u001b[0m (65.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,773</span> (65.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,773\u001b[0m (65.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the number of features\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(input_dim,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Output layer for classification\n",
    "])\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # Suitable for integer labels\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "epochs = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Model checkpoint to save the best model in SavedModel format\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_hand_gesture_model.keras',  # Changed extension to .keras\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m 96/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7901 - loss: 0.6237\n",
      "Epoch 1: val_loss improved from inf to 0.00248, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8254 - loss: 0.5300 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 2/50\n",
      "\u001b[1m 83/125\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0123\n",
      "Epoch 2: val_loss improved from 0.00248 to 0.00035, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 3.5341e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m 83/125\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0046\n",
      "Epoch 3: val_loss improved from 0.00035 to 0.00011, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 1.0891e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m 91/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9968 - loss: 0.0063\n",
      "Epoch 4: val_loss improved from 0.00011 to 0.00006, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 5.5616e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m 93/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0028   \n",
      "Epoch 5: val_loss improved from 0.00006 to 0.00003, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 3.0045e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m 83/125\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0032   \n",
      "Epoch 6: val_loss improved from 0.00003 to 0.00002, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 2.3673e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m 85/125\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011    \n",
      "Epoch 7: val_loss did not improve from 0.00002\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 4.3797e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m 90/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0024\n",
      "Epoch 8: val_loss improved from 0.00002 to 0.00001, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 8.1013e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m 88/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0064   \n",
      "Epoch 9: val_loss improved from 0.00001 to 0.00001, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 5.9765e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m 98/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0038 \n",
      "Epoch 10: val_loss improved from 0.00001 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 3.0167e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m 88/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 6.8075e-04\n",
      "Epoch 11: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 8.8164e-04 - val_accuracy: 1.0000 - val_loss: 2.5300e-06\n",
      "Epoch 12/50\n",
      "\u001b[1m 90/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.5507e-04\n",
      "Epoch 12: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6217e-04 - val_accuracy: 1.0000 - val_loss: 2.0963e-06\n",
      "Epoch 13/50\n",
      "\u001b[1m 89/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.6565e-04\n",
      "Epoch 13: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3523e-04 - val_accuracy: 1.0000 - val_loss: 1.8899e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m 86/125\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.6727e-04\n",
      "Epoch 14: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 2.8592e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m 89/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.5249e-04\n",
      "Epoch 15: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7711e-04 - val_accuracy: 1.0000 - val_loss: 1.1612e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m 89/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.9275e-04\n",
      "Epoch 16: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4814e-04 - val_accuracy: 1.0000 - val_loss: 7.5793e-07\n",
      "Epoch 17/50\n",
      "\u001b[1m 86/125\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0511e-04\n",
      "Epoch 17: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1405e-04 - val_accuracy: 1.0000 - val_loss: 5.6922e-07\n",
      "Epoch 18/50\n",
      "\u001b[1m 90/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.9990e-05\n",
      "Epoch 18: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5400e-05 - val_accuracy: 1.0000 - val_loss: 4.1461e-07\n",
      "Epoch 19/50\n",
      "\u001b[1m 91/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.3573e-04\n",
      "Epoch 19: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5566e-04 - val_accuracy: 1.0000 - val_loss: 3.3259e-07\n",
      "Epoch 20/50\n",
      "\u001b[1m 92/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.9764e-04\n",
      "Epoch 20: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8258e-04 - val_accuracy: 1.0000 - val_loss: 2.5630e-07\n",
      "Epoch 21/50\n",
      "\u001b[1m 84/125\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.2280e-05\n",
      "Epoch 21: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5810e-05 - val_accuracy: 1.0000 - val_loss: 8.1332e-07\n",
      "Epoch 22/50\n",
      "\u001b[1m 90/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 7.7350e-04\n",
      "Epoch 22: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 7.4100e-04 - val_accuracy: 1.0000 - val_loss: 1.2903e-06\n",
      "Epoch 23/50\n",
      "\u001b[1m 88/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.9265e-04\n",
      "Epoch 23: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8770e-04 - val_accuracy: 1.0000 - val_loss: 1.2113e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m 90/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0391e-04\n",
      "Epoch 24: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0360e-04 - val_accuracy: 1.0000 - val_loss: 3.2019e-07\n",
      "Epoch 25/50\n",
      "\u001b[1m 89/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 2.3676e-04\n",
      "Epoch 25: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.8095e-04 - val_accuracy: 1.0000 - val_loss: 1.7022e-06\n",
      "Epoch 26/50\n",
      "\u001b[1m 86/125\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.3513e-05\n",
      "Epoch 26: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2151e-05 - val_accuracy: 1.0000 - val_loss: 3.2436e-07\n",
      "Epoch 27/50\n",
      "\u001b[1m 89/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8669e-04\n",
      "Epoch 27: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1933e-04 - val_accuracy: 1.0000 - val_loss: 1.5306e-07\n",
      "Epoch 28/50\n",
      "\u001b[1m 88/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4579e-04\n",
      "Epoch 28: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6866e-04 - val_accuracy: 1.0000 - val_loss: 3.4571e-08\n",
      "Epoch 29/50\n",
      "\u001b[1m 88/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0014   \n",
      "Epoch 29: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 2.3127e-08\n",
      "Epoch 30/50\n",
      "\u001b[1m 89/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 2.0993e-04\n",
      "Epoch 30: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 6.2468e-04 - val_accuracy: 1.0000 - val_loss: 3.1114e-08\n",
      "Epoch 31/50\n",
      "\u001b[1m 92/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 5.3229e-04\n",
      "Epoch 31: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 5.6330e-04 - val_accuracy: 1.0000 - val_loss: 5.4963e-07\n",
      "Epoch 32/50\n",
      "\u001b[1m107/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 6.8970e-04\n",
      "Epoch 32: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 6.6445e-04 - val_accuracy: 1.0000 - val_loss: 3.9339e-09\n",
      "Epoch 33/50\n",
      "\u001b[1m124/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.4335e-05\n",
      "Epoch 33: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4665e-05 - val_accuracy: 1.0000 - val_loss: 3.4571e-09\n",
      "Epoch 34/50\n",
      "\u001b[1m 88/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 4.3736e-04\n",
      "Epoch 34: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 9.5367e-10\n",
      "Epoch 35/50\n",
      "\u001b[1m 94/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.6014e-05\n",
      "Epoch 35: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 5.9195e-04 - val_accuracy: 1.0000 - val_loss: 1.9431e-07\n",
      "Epoch 36/50\n",
      "\u001b[1m 90/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.7414e-05\n",
      "Epoch 36: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 1.7668e-04 - val_accuracy: 1.0000 - val_loss: 2.9753e-07\n",
      "Epoch 37/50\n",
      "\u001b[1m 90/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0029   \n",
      "Epoch 37: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 1.6689e-09\n",
      "Epoch 38/50\n",
      "\u001b[1m 90/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 5.1759e-04\n",
      "Epoch 38: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 9.7752e-09\n",
      "Epoch 39/50\n",
      "\u001b[1m 89/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.6680e-05\n",
      "Epoch 39: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3502e-05 - val_accuracy: 1.0000 - val_loss: 2.7418e-09\n",
      "Epoch 40/50\n",
      "\u001b[1m 88/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.4313e-05\n",
      "Epoch 40: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6081e-05 - val_accuracy: 1.0000 - val_loss: 6.9141e-09\n",
      "Epoch 41/50\n",
      "\u001b[1m 91/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3492e-05\n",
      "Epoch 41: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9127e-05 - val_accuracy: 1.0000 - val_loss: 9.5367e-10\n",
      "Epoch 42/50\n",
      "\u001b[1m 91/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2799e-05\n",
      "Epoch 42: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7270e-05 - val_accuracy: 1.0000 - val_loss: 5.9605e-10\n",
      "Epoch 43/50\n",
      "\u001b[1m 89/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4264e-05\n",
      "Epoch 43: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5287e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-10\n",
      "Epoch 44/50\n",
      "\u001b[1m 91/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.3831e-06\n",
      "Epoch 44: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3496e-06 - val_accuracy: 1.0000 - val_loss: 1.1921e-10\n",
      "Epoch 45/50\n",
      "\u001b[1m121/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1462e-05\n",
      "Epoch 45: val_loss improved from 0.00000 to 0.00000, saving model to best_hand_gesture_model.keras\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2235e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 46/50\n",
      "\u001b[1m 90/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.3583e-06\n",
      "Epoch 46: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0104e-05 - val_accuracy: 1.0000 - val_loss: 5.6831e-07\n",
      "Epoch 47/50\n",
      "\u001b[1m 89/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0012   \n",
      "Epoch 47: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 5.7220e-09\n",
      "Epoch 48/50\n",
      "\u001b[1m 85/125\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.2771e-05\n",
      "Epoch 48: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6079e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 49/50\n",
      "\u001b[1m 88/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.4834e-06\n",
      "Epoch 49: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5910e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 50/50\n",
      "\u001b[1m 86/125\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.3579e-06\n",
      "Epoch 50: val_loss did not improve from 0.00000\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8167e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f'\\nTest Accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 'hand_gesture_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model to a HDF5 file\n",
    "model.save('hand_gesture_model.h5')\n",
    "print(\"Model saved to 'hand_gesture_model.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "loaded_model = tf.keras.models.load_model('hand_gesture_model.h5')\n",
    "\n",
    "# Load the scaler\n",
    "scaler = joblib.load('scaler.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gesture(landmarks, scaler, model):\n",
    "    \"\"\"\n",
    "    Predicts the gesture class based on normalized landmarks.\n",
    "\n",
    "    Parameters:\n",
    "    - landmarks: List or array of 63 elements (21 landmarks * 3 coordinates)\n",
    "    - scaler: Fitted scaler object\n",
    "    - model: Trained Keras model\n",
    "\n",
    "    Returns:\n",
    "    - Predicted class label\n",
    "    \"\"\"\n",
    "    # Ensure landmarks are a numpy array\n",
    "    landmarks = np.array(landmarks).reshape(1, -1)\n",
    "\n",
    "    # Scale the features\n",
    "    landmarks_scaled = scaler.transform(landmarks)\n",
    "\n",
    "    # Predict probabilities\n",
    "    probabilities = model.predict(landmarks_scaled)\n",
    "\n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(probabilities, axis=1)[0]\n",
    "\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model and scaler\n",
    "loaded_model = tf.keras.models.load_model('hand_gesture_model.h5')\n",
    "scaler = joblib.load('scaler.joblib')\n",
    "\n",
    "# Initialize MediaPipe Hands.\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize video capture from the default webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe Hands.\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,  # Assuming single hand for simplicity\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ") as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a mirror view and convert to RGB.\n",
    "        image = cv2.flip(image, 1)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # To improve performance, mark the image as not writeable.\n",
    "        image_rgb.flags.writeable = False\n",
    "        results = hands.process(image_rgb)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image_rgb.flags.writeable = True\n",
    "        image_output = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        predicted_class = None\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image_output,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)\n",
    "                )\n",
    "                \n",
    "                # Extract landmark coordinates\n",
    "                landmarks = []\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    landmarks.extend([lm.x, lm.y, lm.z])  # Flattened list [x0, y0, z0, ..., x20, y20, z20]\n",
    "\n",
    "                # Normalize landmarks\n",
    "                # Landmark 0 as origin\n",
    "                x0, y0, z0 = landmarks[0], landmarks[1], landmarks[2]\n",
    "                # Distance between landmark 0 and 1\n",
    "                x1, y1, z1 = landmarks[3], landmarks[4], landmarks[5]  # Landmark 1\n",
    "                d01 = np.sqrt((x1 - x0)**2 + (y1 - y0)**2 + (z1 - z0)**2)\n",
    "                if d01 == 0:\n",
    "                    d01 = 1e-6  # Prevent division by zero\n",
    "\n",
    "                # Normalize all landmarks\n",
    "                normalized_landmarks = []\n",
    "                for i in range(0, len(landmarks), 3):\n",
    "                    xi, yi, zi = landmarks[i], landmarks[i+1], landmarks[i+2]\n",
    "                    norm_x = (xi - x0) / d01\n",
    "                    norm_y = (yi - y0) / d01\n",
    "                    norm_z = (zi - z0) / d01\n",
    "                    normalized_landmarks.extend([norm_x, norm_y, norm_z])\n",
    "\n",
    "                # Predict the gesture class\n",
    "                predicted_class = predict_gesture(normalized_landmarks, scaler, loaded_model)\n",
    "\n",
    "        # Display the predicted class on the image\n",
    "        if predicted_class is not None:\n",
    "            cv2.putText(\n",
    "                image_output,\n",
    "                f'Predicted Class: {predicted_class}',\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "        # Show the image\n",
    "        cv2.imshow('Hand Gesture Recognition', image_output)\n",
    "\n",
    "        # Exit the loop when 'q' key is pressed.\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the webcam and close OpenCV windows.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import pyautogui\n",
    "# import time\n",
    "# import platform\n",
    "\n",
    "# # -----------------------------------\n",
    "# # 1. Load the Trained Model and Scaler\n",
    "# # -----------------------------------\n",
    "\n",
    "# # Load the trained Keras model\n",
    "# try:\n",
    "#     loaded_model = tf.keras.models.load_model('hand_gesture_model.keras')\n",
    "#     print(\"Model loaded successfully.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading model: {e}\")\n",
    "#     exit()\n",
    "\n",
    "# # Load the scaler used during training\n",
    "# try:\n",
    "#     scaler = joblib.load('scaler.joblib')\n",
    "#     print(\"Scaler loaded successfully.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading scaler: {e}\")\n",
    "#     exit()\n",
    "\n",
    "# # -----------------------------------\n",
    "# # 2. Define the Prediction Function\n",
    "# # -----------------------------------\n",
    "\n",
    "# def predict_gesture(landmarks, scaler, model):\n",
    "#     \"\"\"\n",
    "#     Predicts the gesture class based on normalized landmarks.\n",
    "\n",
    "#     Parameters:\n",
    "#     - landmarks: List or array of 63 elements (21 landmarks * 3 coordinates)\n",
    "#     - scaler: Fitted scaler object\n",
    "#     - model: Trained Keras model\n",
    "\n",
    "#     Returns:\n",
    "#     - Predicted class label\n",
    "#     \"\"\"\n",
    "#     # Ensure landmarks are a numpy array\n",
    "#     landmarks = np.array(landmarks).reshape(1, -1)\n",
    "\n",
    "#     # Scale the features\n",
    "#     landmarks_scaled = scaler.transform(landmarks)\n",
    "\n",
    "#     # Predict probabilities\n",
    "#     probabilities = model.predict(landmarks_scaled)\n",
    "\n",
    "#     # Get the class with the highest probability\n",
    "#     predicted_class = np.argmax(probabilities, axis=1)[0]\n",
    "\n",
    "#     return predicted_class\n",
    "\n",
    "# # -----------------------------------\n",
    "# # 3. Initialize MediaPipe and PyAutoGUI\n",
    "# # -----------------------------------\n",
    "\n",
    "# # Initialize MediaPipe Hands.\n",
    "# mp_hands = mp.solutions.hands\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# # Initialize video capture from the default webcam.\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Retrieve screen size for mapping landmarks to screen coordinates\n",
    "# screen_width, screen_height = pyautogui.size()\n",
    "# print(f\"Screen Size: {screen_width}x{screen_height}\")\n",
    "\n",
    "# # Initialize variables for action control\n",
    "# last_action_time = 0\n",
    "# action_cooldown = 1  # seconds\n",
    "\n",
    "# # Initialize variables for smoothing (optional)\n",
    "# alpha = 0.2  # Smoothing factor between 0 and 1\n",
    "# current_x, current_y = screen_width // 2, screen_height // 2  # Start at center\n",
    "\n",
    "# # -----------------------------------\n",
    "# # 4. Define Action Functions\n",
    "# # -----------------------------------\n",
    "\n",
    "# def move_mouse(screen_x, screen_y):\n",
    "#     \"\"\"\n",
    "#     Moves the mouse cursor to the specified screen coordinates.\n",
    "\n",
    "#     Parameters:\n",
    "#     - screen_x: X-coordinate on the screen\n",
    "#     - screen_y: Y-coordinate on the screen\n",
    "#     \"\"\"\n",
    "#     # Move the mouse cursor smoothly to the new position\n",
    "#     pyautogui.moveTo(screen_x, screen_y, duration=0.1)\n",
    "\n",
    "# def perform_click():\n",
    "#     \"\"\"\n",
    "#     Performs a mouse click at the current cursor position.\n",
    "#     \"\"\"\n",
    "#     pyautogui.click()\n",
    "\n",
    "# def open_task_view():\n",
    "#     \"\"\"\n",
    "#     Triggers the Windows + Tab key combination to open Task View.\n",
    "#     \"\"\"\n",
    "#     os_name = platform.system()\n",
    "#     if os_name == \"Windows\":\n",
    "#         pyautogui.hotkey('winleft', 'tab')\n",
    "#     elif os_name == \"Darwin\":  # macOS\n",
    "#         pyautogui.hotkey('command', 'tab')\n",
    "#     elif os_name == \"Linux\":\n",
    "#         # Define appropriate key combination based on the DE\n",
    "#         pyautogui.hotkey('alt', 'tab')\n",
    "#     else:\n",
    "#         print(\"Unsupported OS for Task View.\")\n",
    "\n",
    "# def scroll_up():\n",
    "#     \"\"\"\n",
    "#     Scrolls the mouse up.\n",
    "#     \"\"\"\n",
    "#     pyautogui.scroll(100)  # Adjust the scroll amount as needed\n",
    "\n",
    "# def scroll_down():\n",
    "#     \"\"\"\n",
    "#     Scrolls the mouse down.\n",
    "#     \"\"\"\n",
    "#     pyautogui.scroll(-100)  # Negative value for scrolling down\n",
    "\n",
    "# # -----------------------------------\n",
    "# # 5. Real-Time Gesture Recognition Loop\n",
    "# # -----------------------------------\n",
    "\n",
    "# # Initialize MediaPipe Hands.\n",
    "# with mp_hands.Hands(\n",
    "#     static_image_mode=False,\n",
    "#     max_num_hands=1,  # Assuming single hand for simplicity\n",
    "#     min_detection_confidence=0.5,\n",
    "#     min_tracking_confidence=0.5\n",
    "# ) as hands:\n",
    "#     print(\"Starting real-time gesture recognition. Press 'q' to quit.\")\n",
    "#     while cap.isOpened():\n",
    "#         success, image = cap.read()\n",
    "#         if not success:\n",
    "#             print(\"Ignoring empty camera frame.\")\n",
    "#             continue\n",
    "\n",
    "#         # Flip the image horizontally for a mirror view and convert to RGB.\n",
    "#         image = cv2.flip(image, 1)\n",
    "#         image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#         # To improve performance, mark the image as not writeable.\n",
    "#         image_rgb.flags.writeable = False\n",
    "#         results = hands.process(image_rgb)\n",
    "\n",
    "#         # Draw the hand annotations on the image.\n",
    "#         image_rgb.flags.writeable = True\n",
    "#         image_output = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#         predicted_class = None\n",
    "\n",
    "#         if results.multi_hand_landmarks:\n",
    "#             for hand_landmarks in results.multi_hand_landmarks:\n",
    "#                 # Draw landmarks and connections on the image\n",
    "#                 mp_drawing.draw_landmarks(\n",
    "#                     image_output,\n",
    "#                     hand_landmarks,\n",
    "#                     mp_hands.HAND_CONNECTIONS,\n",
    "#                     mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=4),\n",
    "#                     mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)\n",
    "#                 )\n",
    "\n",
    "#                 # Extract landmark coordinates\n",
    "#                 landmarks = []\n",
    "#                 for lm in hand_landmarks.landmark:\n",
    "#                     landmarks.extend([lm.x, lm.y, lm.z])  # Flattened list [x0, y0, z0, ..., x20, y20, z20]\n",
    "\n",
    "#                 # Normalize landmarks\n",
    "#                 # Landmark 0 as origin\n",
    "#                 x0, y0, z0 = landmarks[0], landmarks[1], landmarks[2]\n",
    "#                 # Distance between landmark 0 and 1\n",
    "#                 x1, y1, z1 = landmarks[3], landmarks[4], landmarks[5]  # Landmark 1\n",
    "#                 d01 = np.sqrt((x1 - x0)**2 + (y1 - y0)**2 + (z1 - z0)**2)\n",
    "#                 if d01 == 0:\n",
    "#                     d01 = 1e-6  # Prevent division by zero\n",
    "\n",
    "#                 # Normalize all landmarks\n",
    "#                 normalized_landmarks = []\n",
    "#                 for i in range(0, len(landmarks), 3):\n",
    "#                     xi, yi, zi = landmarks[i], landmarks[i+1], landmarks[i+2]\n",
    "#                     norm_x = (xi - x0) / d01\n",
    "#                     norm_y = (yi - y0) / d01\n",
    "#                     norm_z = (zi - z0) / d01\n",
    "#                     normalized_landmarks.extend([norm_x, norm_y, norm_z])\n",
    "\n",
    "#                 # Predict the gesture class\n",
    "#                 predicted_class = predict_gesture(normalized_landmarks, scaler, loaded_model)\n",
    "\n",
    "#                 # Perform action based on the predicted class\n",
    "#                 current_time = time.time()\n",
    "#                 if current_time - last_action_time > action_cooldown:\n",
    "#                     if predicted_class == 2:\n",
    "#                         # Move the mouse cursor to Landmark 8's position\n",
    "#                         # Landmark 8 corresponds to index 8 in the landmarks list\n",
    "#                         landmark_8_x = landmarks[8 * 3]\n",
    "#                         landmark_8_y = landmarks[8 * 3 + 1]\n",
    "\n",
    "#                         # Calculate absolute positions in the frame\n",
    "#                         frame_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "#                         frame_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "#                         # Debug: Print frame size and absolute landmark positions\n",
    "#                         print(f\"Frame Size: {frame_width}x{frame_height}\")\n",
    "#                         print(f\"Landmark 8 Absolute Position: ({landmark_8_x}, {landmark_8_y})\")\n",
    "\n",
    "#                         absolute_x = int(landmark_8_x * frame_width)\n",
    "#                         absolute_y = int(landmark_8_y * frame_height)\n",
    "\n",
    "#                         # Map the frame coordinates to screen coordinates\n",
    "#                         # Since the image is flipped horizontally, invert the x-coordinate\n",
    "#                         screen_x = int((absolute_x / frame_width) * screen_width)\n",
    "#                         screen_y = int((absolute_y / frame_height) * screen_height)\n",
    "\n",
    "#                         # Debug: Print mapped screen coordinates before clamping\n",
    "#                         print(f\"Mapped Screen Position before clamping: ({screen_x}, {screen_y})\")\n",
    "\n",
    "#                         # Clamp the screen coordinates to be within the screen boundaries\n",
    "#                         screen_x = max(0, min(screen_width - 1, screen_x))\n",
    "#                         screen_y = max(0, min(screen_height - 1, screen_y))\n",
    "\n",
    "#                         # Debug: Print mapped screen coordinates after clamping\n",
    "#                         print(f\"Mapped Screen Position after clamping: ({screen_x}, {screen_y})\")\n",
    "\n",
    "#                         # Apply smoothing (optional)\n",
    "#                         current_x = int(alpha * screen_x + (1 - alpha) * current_x)\n",
    "#                         current_y = int(alpha * screen_y + (1 - alpha) * current_y)\n",
    "\n",
    "#                         # Clamp the smoothed coordinates\n",
    "#                         current_x = max(0, min(screen_width - 1, current_x))\n",
    "#                         current_y = max(0, min(screen_height - 1, current_y))\n",
    "\n",
    "#                         # Debug: Print smoothed screen coordinates\n",
    "#                         print(f\"Smoothed Screen Position: ({current_x}, {current_y})\")\n",
    "\n",
    "#                         move_mouse(current_x, current_y)\n",
    "#                         last_action_time = current_time\n",
    "\n",
    "#                     elif predicted_class == 1:\n",
    "#                         # Perform a mouse click\n",
    "#                         perform_click()\n",
    "#                         print(\"Mouse click performed.\")\n",
    "#                         last_action_time = current_time\n",
    "\n",
    "#                     elif predicted_class == 0:\n",
    "#                         # Trigger Windows + Tab key combination\n",
    "#                         open_task_view()\n",
    "#                         print(\"Opened Task View.\")\n",
    "#                         last_action_time = current_time\n",
    "\n",
    "#                     elif predicted_class == 3:\n",
    "#                         # Perform scroll up\n",
    "#                         scroll_up()\n",
    "#                         print(\"Scrolled Up.\")\n",
    "#                         last_action_time = current_time\n",
    "\n",
    "#                     elif predicted_class == 4:\n",
    "#                         # Perform scroll down\n",
    "#                         scroll_down()\n",
    "#                         print(\"Scrolled Down.\")\n",
    "#                         last_action_time = current_time\n",
    "\n",
    "#         # Display the predicted class on the image\n",
    "#         if predicted_class is not None:\n",
    "#             cv2.putText(\n",
    "#                 image_output,\n",
    "#                 f'Predicted Class: {predicted_class}',\n",
    "#                 (10, 30),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                 1,\n",
    "#                 (0, 255, 0),\n",
    "#                 2,\n",
    "#                 cv2.LINE_AA\n",
    "#             )\n",
    "\n",
    "#         # Show the image in a window\n",
    "#         cv2.imshow('Hand Gesture Recognition', image_output)\n",
    "\n",
    "#         # Exit the loop when 'q' key is pressed.\n",
    "#         if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "#             print(\"Exiting...\")\n",
    "#             break\n",
    "\n",
    "# # -----------------------------------\n",
    "# # 6. Cleanup\n",
    "# # -----------------------------------\n",
    "\n",
    "# # Release the webcam and close OpenCV windows.\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model: File not found: filepath=hand_gesture_model.keras. Please ensure the file is an accessible `.keras` zip file.\n",
      "Scaler loaded successfully.\n",
      "Screen Size: 1920x1080\n",
      "Starting real-time gesture recognition. Press 'q' to quit.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6754286289215088, 0.42675310373306274)\n",
      "Mapped Screen Position before clamping: (1296, 459)\n",
      "Mapped Screen Position after clamping: (1296, 459)\n",
      "Averaged Screen Position: (1027, 523)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6025667786598206, 0.4280751049518585)\n",
      "Mapped Screen Position before clamping: (1155, 461)\n",
      "Mapped Screen Position after clamping: (1155, 461)\n",
      "Averaged Screen Position: (1066, 508)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6630189418792725, 0.4072532057762146)\n",
      "Mapped Screen Position before clamping: (1272, 438)\n",
      "Mapped Screen Position after clamping: (1272, 438)\n",
      "Averaged Screen Position: (1128, 487)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.8214138746261597, 0.4278028607368469)\n",
      "Mapped Screen Position before clamping: (1575, 461)\n",
      "Mapped Screen Position after clamping: (1575, 461)\n",
      "Averaged Screen Position: (1251, 471)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.7346845865249634, 0.4363223612308502)\n",
      "Mapped Screen Position before clamping: (1410, 470)\n",
      "Mapped Screen Position after clamping: (1410, 470)\n",
      "Averaged Screen Position: (1341, 457)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6645325422286987, 0.4473249316215515)\n",
      "Mapped Screen Position before clamping: (1275, 481)\n",
      "Mapped Screen Position after clamping: (1275, 481)\n",
      "Averaged Screen Position: (1337, 462)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6452118754386902, 0.45063942670822144)\n",
      "Mapped Screen Position before clamping: (1236, 486)\n",
      "Mapped Screen Position after clamping: (1236, 486)\n",
      "Averaged Screen Position: (1353, 467)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.5541407465934753, 0.436553955078125)\n",
      "Mapped Screen Position before clamping: (1062, 470)\n",
      "Mapped Screen Position after clamping: (1062, 470)\n",
      "Averaged Screen Position: (1311, 473)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.4694807231426239, 0.3873242735862732)\n",
      "Mapped Screen Position before clamping: (900, 416)\n",
      "Mapped Screen Position after clamping: (900, 416)\n",
      "Averaged Screen Position: (1176, 464)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.4996429979801178, 0.44544869661331177)\n",
      "Mapped Screen Position before clamping: (957, 479)\n",
      "Mapped Screen Position after clamping: (957, 479)\n",
      "Averaged Screen Position: (1086, 466)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.5432104468345642, 0.5261039733886719)\n",
      "Mapped Screen Position before clamping: (1041, 567)\n",
      "Mapped Screen Position after clamping: (1041, 567)\n",
      "Averaged Screen Position: (1039, 483)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.5658469200134277, 0.5323559045791626)\n",
      "Mapped Screen Position before clamping: (1086, 573)\n",
      "Mapped Screen Position after clamping: (1086, 573)\n",
      "Averaged Screen Position: (1009, 501)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6341318488121033, 0.5020381808280945)\n",
      "Mapped Screen Position before clamping: (1215, 540)\n",
      "Mapped Screen Position after clamping: (1215, 540)\n",
      "Averaged Screen Position: (1039, 515)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6673479676246643, 0.4949486255645752)\n",
      "Mapped Screen Position before clamping: (1281, 533)\n",
      "Mapped Screen Position after clamping: (1281, 533)\n",
      "Averaged Screen Position: (1116, 538)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6695441603660583, 0.46638908982276917)\n",
      "Mapped Screen Position before clamping: (1284, 501)\n",
      "Mapped Screen Position after clamping: (1284, 501)\n",
      "Averaged Screen Position: (1181, 542)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6457464098930359, 0.355713427066803)\n",
      "Mapped Screen Position before clamping: (1239, 382)\n",
      "Mapped Screen Position after clamping: (1239, 382)\n",
      "Averaged Screen Position: (1221, 505)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6378071904182434, 0.31929370760917664)\n",
      "Mapped Screen Position before clamping: (1224, 344)\n",
      "Mapped Screen Position after clamping: (1224, 344)\n",
      "Averaged Screen Position: (1248, 460)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.7051747441291809, 0.3519779443740845)\n",
      "Mapped Screen Position before clamping: (1353, 378)\n",
      "Mapped Screen Position after clamping: (1353, 378)\n",
      "Averaged Screen Position: (1276, 427)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.8017765283584595, 0.4006560742855072)\n",
      "Mapped Screen Position before clamping: (1539, 432)\n",
      "Mapped Screen Position after clamping: (1539, 432)\n",
      "Averaged Screen Position: (1327, 407)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.8568276762962341, 0.41704192757606506)\n",
      "Mapped Screen Position before clamping: (1644, 450)\n",
      "Mapped Screen Position after clamping: (1644, 450)\n",
      "Averaged Screen Position: (1399, 397)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.8821327686309814, 0.4267549216747284)\n",
      "Mapped Screen Position before clamping: (1692, 459)\n",
      "Mapped Screen Position after clamping: (1692, 459)\n",
      "Averaged Screen Position: (1490, 412)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.7447224259376526, 0.3816555142402649)\n",
      "Mapped Screen Position before clamping: (1428, 411)\n",
      "Mapped Screen Position after clamping: (1428, 411)\n",
      "Averaged Screen Position: (1531, 426)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.5269779562950134, 0.36515527963638306)\n",
      "Mapped Screen Position before clamping: (1011, 393)\n",
      "Mapped Screen Position after clamping: (1011, 393)\n",
      "Averaged Screen Position: (1462, 429)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.38199618458747864, 0.3246392011642456)\n",
      "Mapped Screen Position before clamping: (732, 348)\n",
      "Mapped Screen Position after clamping: (732, 348)\n",
      "Averaged Screen Position: (1301, 412)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.28503620624542236, 0.3111215829849243)\n",
      "Mapped Screen Position before clamping: (546, 335)\n",
      "Mapped Screen Position after clamping: (546, 335)\n",
      "Averaged Screen Position: (1081, 389)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.30338534712791443, 0.28146108984947205)\n",
      "Mapped Screen Position before clamping: (582, 303)\n",
      "Mapped Screen Position after clamping: (582, 303)\n",
      "Averaged Screen Position: (859, 358)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6644493937492371, 0.5140911936759949)\n",
      "Mapped Screen Position before clamping: (1275, 553)\n",
      "Mapped Screen Position after clamping: (1275, 553)\n",
      "Averaged Screen Position: (829, 386)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.5976008772850037, 0.4018020033836365)\n",
      "Mapped Screen Position before clamping: (1146, 432)\n",
      "Mapped Screen Position after clamping: (1146, 432)\n",
      "Averaged Screen Position: (856, 394)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Opened Task View.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Opened Task View.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Opened Task View.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6078680157661438, 0.42824792861938477)\n",
      "Mapped Screen Position before clamping: (1167, 461)\n",
      "Mapped Screen Position after clamping: (1167, 461)\n",
      "Averaged Screen Position: (943, 416)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.7908610701560974, 0.3549680709838867)\n",
      "Mapped Screen Position before clamping: (1518, 382)\n",
      "Mapped Screen Position after clamping: (1518, 382)\n",
      "Averaged Screen Position: (1137, 426)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.8625975251197815, 0.2959963083267212)\n",
      "Mapped Screen Position before clamping: (1656, 319)\n",
      "Mapped Screen Position after clamping: (1656, 319)\n",
      "Averaged Screen Position: (1352, 429)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.8409189581871033, 0.23205819725990295)\n",
      "Mapped Screen Position before clamping: (1614, 249)\n",
      "Mapped Screen Position after clamping: (1614, 249)\n",
      "Averaged Screen Position: (1420, 368)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.7938045263290405, 0.2207413762807846)\n",
      "Mapped Screen Position before clamping: (1524, 236)\n",
      "Mapped Screen Position after clamping: (1524, 236)\n",
      "Averaged Screen Position: (1495, 329)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.76329106092453, 0.23540818691253662)\n",
      "Mapped Screen Position before clamping: (1464, 252)\n",
      "Mapped Screen Position after clamping: (1464, 252)\n",
      "Averaged Screen Position: (1555, 287)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Mouse click performed.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.7556588649749756, 0.28264549374580383)\n",
      "Mapped Screen Position before clamping: (1449, 303)\n",
      "Mapped Screen Position after clamping: (1449, 303)\n",
      "Averaged Screen Position: (1541, 271)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.6309401392936707, 0.432007372379303)\n",
      "Mapped Screen Position before clamping: (1209, 465)\n",
      "Mapped Screen Position after clamping: (1209, 465)\n",
      "Averaged Screen Position: (1452, 301)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.5831140875816345, 0.4826233983039856)\n",
      "Mapped Screen Position before clamping: (1119, 519)\n",
      "Mapped Screen Position after clamping: (1119, 519)\n",
      "Averaged Screen Position: (1353, 355)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Started Scrolling Down.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Started Scrolling Down.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Started Scrolling Down.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Started Scrolling Down.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Started Scrolling Down.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "Started Scrolling Down.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "Started Scrolling Up.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Started Scrolling Up.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "Frame Size: 640.0x480.0\n",
      "Landmark 8 Absolute Position: (0.623180627822876, 0.4307519197463989)\n",
      "Mapped Screen Position before clamping: (1194, 463)\n",
      "Mapped Screen Position after clamping: (1194, 463)\n",
      "Averaged Screen Position: (1287, 400)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import joblib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "import platform\n",
    "import threading\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. Load the Trained Model and Scaler\n",
    "# -----------------------------------\n",
    "\n",
    "# Load the trained Keras model\n",
    "try:\n",
    "    loaded_model = tf.keras.models.load_model('hand_gesture_model.keras')\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Load the scaler used during training\n",
    "try:\n",
    "    scaler = joblib.load('scaler.joblib')\n",
    "    print(\"Scaler loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading scaler: {e}\")\n",
    "    exit()\n",
    "\n",
    "# -----------------------------------\n",
    "# 2. Define the Prediction Function\n",
    "# -----------------------------------\n",
    "\n",
    "def predict_gesture(landmarks, scaler, model):\n",
    "    \"\"\"\n",
    "    Predicts the gesture class based on normalized landmarks.\n",
    "\n",
    "    Parameters:\n",
    "    - landmarks: List or array of 63 elements (21 landmarks * 3 coordinates)\n",
    "    - scaler: Fitted scaler object\n",
    "    - model: Trained Keras model\n",
    "\n",
    "    Returns:\n",
    "    - Predicted class label\n",
    "    \"\"\"\n",
    "    # Ensure landmarks are a numpy array\n",
    "    landmarks = np.array(landmarks).reshape(1, -1)\n",
    "\n",
    "    # Scale the features\n",
    "    landmarks_scaled = scaler.transform(landmarks)\n",
    "\n",
    "    # Predict probabilities\n",
    "    probabilities = model.predict(landmarks_scaled)\n",
    "\n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = np.argmax(probabilities, axis=1)[0]\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# -----------------------------------\n",
    "# 3. Initialize MediaPipe and PyAutoGUI\n",
    "# -----------------------------------\n",
    "\n",
    "# Initialize MediaPipe Hands.\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize video capture from the default webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Retrieve screen size for mapping landmarks to screen coordinates\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "print(f\"Screen Size: {screen_width}x{screen_height}\")\n",
    "\n",
    "# Initialize variables for action control\n",
    "last_action_time = 0\n",
    "action_cooldown = 1  # seconds\n",
    "\n",
    "# Initialize variables for smoothing (optional)\n",
    "alpha = 0.2  # Smoothing factor between 0 and 1\n",
    "current_x, current_y = screen_width // 2, screen_height // 2  # Start at center\n",
    "\n",
    "# -----------------------------------\n",
    "# 4. Define Action Functions\n",
    "# -----------------------------------\n",
    "\n",
    "def move_mouse(screen_x, screen_y):\n",
    "    \"\"\"\n",
    "    Moves the mouse cursor to the specified screen coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - screen_x: X-coordinate on the screen\n",
    "    - screen_y: Y-coordinate on the screen\n",
    "    \"\"\"\n",
    "    # Move the mouse cursor smoothly to the new position\n",
    "    pyautogui.moveTo(screen_x, screen_y, duration=0.05)\n",
    "\n",
    "def perform_click():\n",
    "    \"\"\"\n",
    "    Performs a mouse click at the current cursor position.\n",
    "    \"\"\"\n",
    "    pyautogui.click()\n",
    "\n",
    "def open_task_view():\n",
    "    \"\"\"\n",
    "    Triggers the Windows + Tab key combination to open Task View.\n",
    "    \"\"\"\n",
    "    os_name = platform.system()\n",
    "    if os_name == \"Windows\":\n",
    "        pyautogui.hotkey('winleft', 'tab')\n",
    "    elif os_name == \"Darwin\":  # macOS\n",
    "        pyautogui.hotkey('command', 'tab')\n",
    "    elif os_name == \"Linux\":\n",
    "        # Define appropriate key combination based on the DE\n",
    "        pyautogui.hotkey('alt', 'tab')\n",
    "    else:\n",
    "        print(\"Unsupported OS for Task View.\")\n",
    "\n",
    "def scroll_up():\n",
    "    \"\"\"\n",
    "    Scrolls the mouse up smoothly.\n",
    "    \"\"\"\n",
    "    pyautogui.scroll(scroll_amount)\n",
    "\n",
    "def scroll_down():\n",
    "    \"\"\"\n",
    "    Scrolls the mouse down smoothly.\n",
    "    \"\"\"\n",
    "    pyautogui.scroll(-scroll_amount)\n",
    "\n",
    "# -----------------------------------\n",
    "# 5. Implement Continuous Scrolling\n",
    "# -----------------------------------\n",
    "\n",
    "class ScrollController:\n",
    "    \"\"\"\n",
    "    Controls smooth scrolling based on gesture detection.\n",
    "    \"\"\"\n",
    "    def __init__(self, scroll_up_func, scroll_down_func, interval=0.05):\n",
    "        self.scroll_up_func = scroll_up_func\n",
    "        self.scroll_down_func = scroll_down_func\n",
    "        self.interval = interval\n",
    "        self.is_scrolling_up = False\n",
    "        self.is_scrolling_down = False\n",
    "        self.thread = None\n",
    "        self.stop_event = threading.Event()\n",
    "\n",
    "    def start_scrolling(self):\n",
    "        if self.thread is None or not self.thread.is_alive():\n",
    "            self.stop_event.clear()\n",
    "            self.thread = threading.Thread(target=self.scroll_loop)\n",
    "            self.thread.start()\n",
    "\n",
    "    def stop_scrolling(self):\n",
    "        self.stop_event.set()\n",
    "        if self.thread is not None:\n",
    "            self.thread.join()\n",
    "\n",
    "    def scroll_loop(self):\n",
    "        while not self.stop_event.is_set():\n",
    "            if self.is_scrolling_up:\n",
    "                self.scroll_up_func()\n",
    "            if self.is_scrolling_down:\n",
    "                self.scroll_down_func()\n",
    "            time.sleep(self.interval)\n",
    "\n",
    "    def set_scroll_direction(self, direction):\n",
    "        \"\"\"\n",
    "        Sets the scroll direction.\n",
    "\n",
    "        Parameters:\n",
    "        - direction: 'up', 'down', or None\n",
    "        \"\"\"\n",
    "        if direction == 'up':\n",
    "            self.is_scrolling_up = True\n",
    "            self.is_scrolling_down = False\n",
    "            self.start_scrolling()\n",
    "        elif direction == 'down':\n",
    "            self.is_scrolling_down = True\n",
    "            self.is_scrolling_up = False\n",
    "            self.start_scrolling()\n",
    "        else:\n",
    "            self.is_scrolling_up = False\n",
    "            self.is_scrolling_down = False\n",
    "            self.stop_scrolling()\n",
    "\n",
    "# Define scrolling parameters\n",
    "scroll_amount = 20      # Amount to scroll per action (adjust as needed)\n",
    "scroll_interval = 0.05  # Time interval between scroll actions in seconds\n",
    "\n",
    "# Initialize ScrollController\n",
    "scroll_controller = ScrollController(scroll_up, scroll_down, interval=scroll_interval)\n",
    "\n",
    "# -----------------------------------\n",
    "# 6. Real-Time Gesture Recognition Loop\n",
    "# -----------------------------------\n",
    "\n",
    "# Initialize MediaPipe Hands.\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,  # Assuming single hand for simplicity\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ") as hands:\n",
    "    print(\"Starting real-time gesture recognition. Press 'q' to quit.\")\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a mirror view and convert to RGB.\n",
    "        image = cv2.flip(image, 1)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # To improve performance, mark the image as not writeable.\n",
    "        image_rgb.flags.writeable = False\n",
    "        results = hands.process(image_rgb)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image_rgb.flags.writeable = True\n",
    "        image_output = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        predicted_class = None\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Draw landmarks and connections on the image\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image_output,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)\n",
    "                )\n",
    "\n",
    "                # Extract landmark coordinates\n",
    "                landmarks = []\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    landmarks.extend([lm.x, lm.y, lm.z])  # Flattened list [x0, y0, z0, ..., x20, y20, z20]\n",
    "\n",
    "                # Normalize landmarks\n",
    "                # Landmark 0 as origin\n",
    "                x0, y0, z0 = landmarks[0], landmarks[1], landmarks[2]\n",
    "                # Distance between landmark 0 and 1\n",
    "                x1, y1, z1 = landmarks[3], landmarks[4], landmarks[5]  # Landmark 1\n",
    "                d01 = np.sqrt((x1 - x0)**2 + (y1 - y0)**2 + (z1 - z0)**2)\n",
    "                if d01 == 0:\n",
    "                    d01 = 1e-6  # Prevent division by zero\n",
    "\n",
    "                # Normalize all landmarks\n",
    "                normalized_landmarks = []\n",
    "                for i in range(0, len(landmarks), 3):\n",
    "                    xi, yi, zi = landmarks[i], landmarks[i+1], landmarks[i+2]\n",
    "                    norm_x = (xi - x0) / d01\n",
    "                    norm_y = (yi - y0) / d01\n",
    "                    norm_z = (zi - z0) / d01\n",
    "                    normalized_landmarks.extend([norm_x, norm_y, norm_z])\n",
    "\n",
    "                # Predict the gesture class\n",
    "                predicted_class = predict_gesture(normalized_landmarks, scaler, loaded_model)\n",
    "\n",
    "                # Perform action based on the predicted class\n",
    "                current_time = time.time()\n",
    "                if current_time - last_action_time > action_cooldown:\n",
    "                    if predicted_class == 2:\n",
    "                        # Move the mouse cursor to Landmark 8's position\n",
    "                        # Landmark 8 corresponds to index 8 in the landmarks list\n",
    "                        landmark_8_x = landmarks[8 * 3]\n",
    "                        landmark_8_y = landmarks[8 * 3 + 1]\n",
    "\n",
    "                        # Calculate absolute positions in the frame\n",
    "                        frame_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "                        frame_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "                        # Debug: Print frame size and absolute landmark positions\n",
    "                        print(f\"Frame Size: {frame_width}x{frame_height}\")\n",
    "                        print(f\"Landmark 8 Absolute Position: ({landmark_8_x}, {landmark_8_y})\")\n",
    "\n",
    "                        absolute_x = int(landmark_8_x * frame_width)\n",
    "                        absolute_y = int(landmark_8_y * frame_height)\n",
    "\n",
    "                        # Map the frame coordinates to screen coordinates\n",
    "                        # Since the image is flipped horizontally, invert the x-coordinate\n",
    "                        screen_x = int((absolute_x / frame_width) * screen_width)\n",
    "                        screen_y = int((absolute_y / frame_height) * screen_height)\n",
    "\n",
    "                        # Debug: Print mapped screen coordinates before clamping\n",
    "                        print(f\"Mapped Screen Position before clamping: ({screen_x}, {screen_y})\")\n",
    "\n",
    "                        # Clamp the screen coordinates to be within the screen boundaries\n",
    "                        screen_x = max(0, min(screen_width - 1, screen_x))\n",
    "                        screen_y = max(0, min(screen_height - 1, screen_y))\n",
    "\n",
    "                        # Debug: Print mapped screen coordinates after clamping\n",
    "                        print(f\"Mapped Screen Position after clamping: ({screen_x}, {screen_y})\")\n",
    "\n",
    "                        # Apply smoothing (optional)\n",
    "                        current_x = int(alpha * screen_x + (1 - alpha) * current_x)\n",
    "                        current_y = int(alpha * screen_y + (1 - alpha) * current_y)\n",
    "\n",
    "                        # Clamp the smoothed coordinates\n",
    "                        current_x = max(0, min(screen_width - 1, current_x))\n",
    "                        current_y = max(0, min(screen_height - 1, current_y))\n",
    "\n",
    "                        # Debug: Print smoothed screen coordinates\n",
    "                        print(f\"Smoothed Screen Position: ({current_x}, {current_y})\")\n",
    "\n",
    "                        move_mouse(current_x, current_y)\n",
    "                        last_action_time = current_time\n",
    "\n",
    "                        # Stop any ongoing scrolling\n",
    "                        scroll_controller.set_scroll_direction(None)\n",
    "\n",
    "                    elif predicted_class == 1:\n",
    "                        # Perform a mouse click\n",
    "                        perform_click()\n",
    "                        print(\"Mouse click performed.\")\n",
    "                        last_action_time = current_time\n",
    "\n",
    "                        # Stop any ongoing scrolling\n",
    "                        scroll_controller.set_scroll_direction(None)\n",
    "\n",
    "                    elif predicted_class == 0:\n",
    "                        # Trigger Windows + Tab key combination\n",
    "                        open_task_view()\n",
    "                        print(\"Opened Task View.\")\n",
    "                        last_action_time = current_time\n",
    "\n",
    "                        # Stop any ongoing scrolling\n",
    "                        scroll_controller.set_scroll_direction(None)\n",
    "\n",
    "                    elif predicted_class == 3:\n",
    "                        # Start scrolling up\n",
    "                        scroll_controller.set_scroll_direction('up')\n",
    "                        print(\"Started Scrolling Up.\")\n",
    "                        last_action_time = current_time\n",
    "\n",
    "                    elif predicted_class == 4:\n",
    "                        # Start scrolling down\n",
    "                        scroll_controller.set_scroll_direction('down')\n",
    "                        print(\"Started Scrolling Down.\")\n",
    "                        last_action_time = current_time\n",
    "\n",
    "        # Display the predicted class on the image\n",
    "        if predicted_class is not None:\n",
    "            cv2.putText(\n",
    "                image_output,\n",
    "                f'Predicted Class: {predicted_class}',\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "        # Show the image in a window\n",
    "        cv2.imshow('Hand Gesture Recognition', image_output)\n",
    "\n",
    "        # Emergency Stop: Press 'e' to exit immediately\n",
    "        if cv2.waitKey(5) & 0xFF == ord('e'):\n",
    "            print(\"Emergency Stop Activated. Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Exit the loop when 'q' key is pressed.\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "# -----------------------------------\n",
    "# 7. Cleanup\n",
    "# -----------------------------------\n",
    "\n",
    "# Stop any ongoing scrolling\n",
    "scroll_controller.set_scroll_direction(None)\n",
    "\n",
    "# Release the webcam and close OpenCV windows.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hand_gesture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
